import { Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import OpenAI from 'openai';
import {
  ChatCompletionMessageParam,
  ChatCompletionTool,
} from 'openai/resources/chat/completions';

import { AIProvider } from '../interfaces/ai-provider-interface';

/**
 * ü§ñ DeepSeek Provider - Vers√£o Simplificada e Consolidada
 *
 * RESPONSABILIDADES:
 * 1. Comunicar com a API DeepSeek
 * 2. Gerar respostas com function calling
 * 3. Gerenciar configura√ß√µes da API
 *
 * FLUXO:
 * 1. Recebe mensagens e tools
 * 2. Envia para DeepSeek API
 * 3. Retorna resposta da IA
 */
export class DeepseekProvider implements AIProvider {
  private readonly logger = new Logger(DeepseekProvider.name);
  private readonly client: OpenAI;
  private readonly model: string = 'deepseek-chat';

  constructor(private readonly configService: ConfigService) {
    this.logger.log('üîß [DEEPSEEK] Inicializando DeepSeek Provider...');

    const apiKey = this.configService.get<string>('DEEPSEEK_API_KEY');
    const baseURL =
      this.configService.get<string>('DEEPSEEK_BASE_URL') ||
      'https://api.deepseek.com';

    if (!apiKey) {
      this.logger.error('‚ùå [DEEPSEEK] DEEPSEEK_API_KEY n√£o configurada');
      throw new Error('DEEPSEEK_API_KEY √© obrigat√≥ria');
    }

    this.client = new OpenAI({
      apiKey,
      baseURL,
    });

    this.logger.log(
      `‚úÖ [DEEPSEEK] Provider inicializado com baseURL: ${baseURL}`,
    );
  }

  /**
   * üéØ M√âTODO PRINCIPAL - Gera resposta da IA
   *
   * @param messages Array de mensagens para enviar
   * @param tools Tools dispon√≠veis para function calling (opcional)
   * @returns Promise<OpenAI.Chat.Completions.ChatCompletionMessage>
   *
   * @example
   * ```typescript
   * const messages = [
   *   { role: 'system', content: 'Voc√™ √© um assistente √∫til.' },
   *   { role: 'user', content: 'Quero ver os planos' }
   * ];
   *
   * const tools = toolRegistry.getChatCompletionTools();
   * const response = await deepseekProvider.generateResponse(messages, tools);
   * ```
   */
  async generateResponse(
    messages: ChatCompletionMessageParam[],
    tools?: ChatCompletionTool[],
  ): Promise<OpenAI.Chat.Completions.ChatCompletionMessage> {
    this.logger.log('ü§ñ [DEEPSEEK] Iniciando gera√ß√£o de resposta...');
    this.logger.log(`ü§ñ [DEEPSEEK] Mensagens: ${messages.length}`);
    this.logger.log(`ü§ñ [DEEPSEEK] Tools: ${tools?.length || 0}`);

    if (tools && tools.length > 0) {
      this.logger.log(
        `ü§ñ [DEEPSEEK] Tools dispon√≠veis: ${tools.map((t) => t.function.name).join(', ')}`,
      );
    }

    try {
      const completion = await this.client.chat.completions.create({
        model: this.model,
        messages,
        tools,
        max_tokens: 1000,
        temperature: 0.7,
        tool_choice: tools && tools.length > 0 ? 'auto' : undefined,
      });

      const response = completion.choices[0].message;

      this.logger.log(
        'ü§ñ [DEEPSEEK] Resposta completa da API:',
        JSON.stringify(completion, null, 2),
      );
      this.logger.log('‚úÖ [DEEPSEEK] Resposta gerada com sucesso');

      return response;
    } catch (error: any) {
      this.logger.error('‚ùå [DEEPSEEK] Erro ao gerar resposta:', error);
      this.logger.error(
        '‚ùå [DEEPSEEK] Detalhes do erro:',
        error?.message || error,
      );

      // Retornar mensagem de erro padr√£o
      return {
        role: 'assistant',
        content:
          'Desculpe, ocorreu um erro ao processar sua mensagem. Tente novamente.',
        refusal: null,
      };
    }
  }

  /**
   * üìä ESTAT√çSTICAS - Informa√ß√µes sobre o provider
   *
   * @returns Informa√ß√µes de configura√ß√£o
   */
  getStats(): { model: string; baseURL: string; isConfigured: boolean } {
    const baseURL =
      this.configService.get<string>('DEEPSEEK_BASE_URL') ||
      'https://api.deepseek.com';
    const apiKey = this.configService.get<string>('DEEPSEEK_API_KEY');

    return {
      model: this.model,
      baseURL,
      isConfigured: !!apiKey,
    };
  }
}
